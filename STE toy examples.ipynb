{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emotional-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alleged-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for experiment\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # making sure GPU runs are deterministic even if they are slower\n",
    "    print(\"Seeded everything: {}\".format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protected-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded everything: 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-jungle",
   "metadata": {},
   "source": [
    "# Test how the straight through estimator works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-mailman",
   "metadata": {},
   "source": [
    "$$\\text{With indicators:}\\quad f(x_1, x_2) = \\mathbb{1}_{x_1 > 5}x_1^2 + \\mathbb{1}_{x_2 > 5}x_2^2$$\n",
    "$$\\text{Without indicators:}\\quad g(x_1, x_2) = x_1^2 + x_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 1_{x > 5}\n",
    "class GetIndicators(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        \"\"\"\n",
    "            In the forward pass we receive a Tensor containing the input and return\n",
    "            a Tensor containing the output. ctx is a context object that can be used\n",
    "            to stash information for backward computation. You can cache arbitrary\n",
    "            objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        mask = (x > 5).int()\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, g):\n",
    "        \"\"\"\n",
    "            In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "            with respect to the output, and we need to compute the gradient of the loss\n",
    "            with respect to the input.\n",
    "            NOTE: We need only \"g\" here because we have only one input -> x\n",
    "        \"\"\"\n",
    "        # send the gradient g straight-through on the backward pass.\n",
    "        print(\"Incoming grad = Outgoing grad = {}\".format(g))\n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-reviewer",
   "metadata": {},
   "source": [
    "## See if the indicator function works as expected (it does)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enclosed-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1, 6])\n",
    "GetIndicators.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "boolean-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    mask = GetIndicators.apply(x)\n",
    "    out = (mask * x** 2).sum()\n",
    "    return out\n",
    "\n",
    "def g(x):\n",
    "    out = (x**2).sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-defense",
   "metadata": {},
   "source": [
    "$$\\nabla g(x) = \\begin{bmatrix} 2x_1\\\\ 2x_2 \\end{bmatrix}$$\n",
    "\n",
    "### Assuming STE\n",
    "$$\\frac{\\partial f(x)}{\\partial x_i} =  ?$$\n",
    "\n",
    "### Now check if that is what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad(f(x)) = tensor([ 0., 12.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2, 6])\n",
    "x.requires_grad=True\n",
    "f_out = f(x)\n",
    "f_out.backward()\n",
    "print(\"grad(f(x)) = {}\".format(x.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "parallel-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad(g(x)) = tensor([ 4., 12.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2, 6])\n",
    "x.requires_grad=True\n",
    "g_out = g(x)\n",
    "g_out.backward()\n",
    "print(\"grad(g(x)) = {}\".format(x.grad.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-assist",
   "metadata": {},
   "source": [
    "## This doesn't make sense. The gradient of g is as expected (2x) but the gradient of f seems to be $\\frac{\\partial f(x)}{\\partial x_i} = \\mathbb{1}_{x_i > 5} 2x_i$? I expected it to apply the chain rule and then use the STE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
