{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worse-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded everything: 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t = 0.5\n",
    "seed = 42\n",
    "MAX_EPOCHS = int(1e6)\n",
    "\n",
    "# problem setup: min( ||p*a - t||^2 + \\lambda*\\sum{(p_i)*(1-p_i)*a_i^2})\n",
    "\n",
    "def get_regularization(n, p, a, i=0):\n",
    "    reg = torch.sum(p * (1-p) * torch.pow(a, 2))\n",
    "    if i == 0:\n",
    "        lmbda = 1.0\n",
    "    elif i == 1:\n",
    "        lmbda = 1.0/(n**math.log(n))\n",
    "    elif i == 2:\n",
    "        lmbda = 1.0/n\n",
    "    elif i == 3:\n",
    "        lmbda = 1/n**2\n",
    "    else:\n",
    "        lmbda = 0\n",
    "    \n",
    "    reg = lmbda * reg\n",
    "    return reg\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    print(\"Seeded everything: {}\".format(seed))\n",
    "    \n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide regularizer\n",
    "\n",
    "def subset_sum(num_samples=10, regularizer=0):\n",
    "    a = torch.zeros(num_samples)\n",
    "    p = nn.Parameter(torch.Tensor(a.size()))\n",
    "    a.requires_grad = False\n",
    "    p_list = []\n",
    "    loss_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "                [p],\n",
    "                lr=0.01,\n",
    "                weight_decay=0)\n",
    "\n",
    "    # initialize a as uniform [-1, 1]\n",
    "    nn.init.uniform_(a, a=-1, b=1)\n",
    "    nn.init.normal_(p, mean=0.5)\n",
    "    p.data = torch.clamp(p.data, 0.0, 1.0)\n",
    "\n",
    "    for num_iter in range(MAX_EPOCHS):\n",
    "        optimizer.zero_grad()\n",
    "        loss = (t - torch.sum(p*a))**2 + get_regularization(num_samples, p, a, i=regularizer)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        epoch_list.append(num_iter)\n",
    "        p_list.append(p.data)\n",
    "        if num_iter % 100000 == 0 and num_iter != 0:\n",
    "            print(\"Iteration={} | Loss={}\".format(num_iter, loss))\n",
    "        p.data = torch.clamp(p.data, 0.0, 1.0)\n",
    "        if num_iter > 5 and loss.item() == loss_list[-2]:\n",
    "            # print(\"Iteration={} | Converged\".format(num_iter))\n",
    "            break\n",
    "        \n",
    "    min_error = (1.0/num_samples)**np.log(num_samples)\n",
    "    # print(\"Minimum Error = {}\".format(min_error))\n",
    "    results_df = pd.DataFrame({'epoch': epoch_list, 'loss': loss_list})\n",
    "    return min_error, p, results_df\n",
    "\n",
    "def get_frac_nonzeros(x, num_samples):\n",
    "    num_middle = torch.sum(torch.gt(x,\n",
    "                           torch.ones_like(x)*0) *\n",
    "                           torch.lt(x,\n",
    "                           torch.ones_like(x*(1)).int()))\n",
    "    return 1.0*num_middle/num_samples\n",
    "\n",
    "def get_dist_to_vertex(x):\n",
    "    rounded_x = torch.gt(x, torch.ones_like(x)*0.5).int().float()\n",
    "    return torch.norm(x-rounded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples = 100.0\n",
      "Regularizer = 0 | Error_ratio=262636.16966381756 | Final error=0.00016181328101083636 | Minimum error=6.161119438269389e-10 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 1 | Error_ratio=827252.2892519373 | Final error=0.0005096800159662962 | Minimum error=6.161119438269389e-10 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 2 | Error_ratio=4426.375523687913 | Final error=2.727142828007345e-06 | Minimum error=6.161119438269389e-10 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 3 | Error_ratio=11015.96240943746 | Final error=6.7870660132030025e-06 | Minimum error=6.161119438269389e-10 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 4 | Error_ratio=1257533.1925051364 | Final error=0.0007747812196612358 | Minimum error=6.161119438269389e-10 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Num Samples = 1000.0\n",
      "Regularizer = 0 | Error_ratio=1287913568553.491 | Final error=2.4356836547667626e-09 | Minimum error=1.8911856464889798e-21 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 1 | Error_ratio=32166737704699.117 | Final error=6.083327264150284e-08 | Minimum error=1.8911856464889798e-21 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 2 | Error_ratio=300137453152879.6 | Final error=5.676156433764845e-07 | Minimum error=1.8911856464889798e-21 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 3 | Error_ratio=56085090684118.59 | Final error=1.0606731848383788e-07 | Minimum error=1.8911856464889798e-21 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n",
      "Regularizer = 4 | Error_ratio=69251391209.76552 | Final error=1.3096723705530167e-10 | Minimum error=1.8911856464889798e-21 | frac_nonzeros=0.0 | dist_to_veretx=0.0\n"
     ]
    }
   ],
   "source": [
    "avg_error_ratios = []\n",
    "for num_samples in [1e2, 1e3,]:\n",
    "    print(\"Num Samples = {}\".format(num_samples))\n",
    "    error_ratio_list = []\n",
    "    for i in range(1):\n",
    "        for reg in range(5):\n",
    "            num_samples = int(num_samples)\n",
    "            min_error, p_final, results_df = subset_sum(num_samples, 0)\n",
    "            final_error = results_df.tail(1).loss.item()\n",
    "            frac_nonzeros = get_frac_nonzeros(p_final, num_samples)\n",
    "            dist_to_vertex = get_dist_to_vertex(p_final)\n",
    "            print(\"Regularizer = {} | Error_ratio={} | Final error={} | Minimum error={} | frac_nonzeros={} | dist_to_veretx={}\".\\\n",
    "                  format(reg, final_error/min_error, final_error, min_error, frac_nonzeros, dist_to_vertex))\n",
    "            error_ratio = final_error/min_error\n",
    "            error_ratio_list.append(error_ratio)\n",
    "        avg_error_ratio = 1.0*sum(error_ratio_list)/len(error_ratio_list)\n",
    "        avg_error_ratios.append(avg_error_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-genesis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-housing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
