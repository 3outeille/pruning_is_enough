subfolder: transformer
arch: 'transformer'
algo: 'hc_iter'
seed: 42

# ===== Data ===== #
data: ./transformer_data/wikitext-2
batch_size: 20

# ===== Training ===== #
epochs: 6
optimizer: sgd
lr: 5.
lr_policy: multistep_lr
lr_gamma: 0.25
# wd: 0.0

# ===== Network ===== #
bias: False 
conv_type: SubnetConv
bn_type: NonAffineBatchNorm
init: signed_constant
score_init: unif
scale_fan: False

# ===== Finetune ===== #
fine_tune_lr: 5
fine_tune_wd: 0.0
momentum: 0.

# ===== Sparsity ===== #
freeze_weights: True
prune_type: BottomK
target_sparsity: 50.0
unflag_before_finetune: True
iter_period: 1  # 5

# ===== Rounding ===== #
round: naive 
noise: True
noise_ratio: 0

# ===== Quantization ===== #
hc_quantized: True
quantize_threshold: 0.5

# ===== Regularization ===== #
regularization: L2
lmbda: 0.00001

# ===== Hardware setup ===== #
workers: 4
